{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies \n",
    "from fastai.vision.all import *\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from utils import get_y, create_dls, get_mean_table, dataset_forecast, adapt_model_to_new_dls, create_dls_stratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_dls_stratified() got an unexpected keyword argument 'train_pct'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dls \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dls_stratified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/FieldPlant/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: create_dls_stratified() got an unexpected keyword argument 'train_pct'"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "dls = create_dls_stratified(train_pct=0.8, path='data/FieldPlant/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dls \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dls_stratified\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/FieldPlant/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m timm\u001b[38;5;241m.\u001b[39mcreate_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefficientnet_b0\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_classes\u001b[38;5;241m=\u001b[39mdls\u001b[38;5;241m.\u001b[39mc)\n\u001b[0;32m      3\u001b[0m learn \u001b[38;5;241m=\u001b[39m Learner(dls, model, metrics\u001b[38;5;241m=\u001b[39maccuracy)\n",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m, in \u001b[0;36mcreate_dls_stratified\u001b[1;34m(path, train_size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_dls_stratified\u001b[39m(path, train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Gather all image file paths and their corresponding labels\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[43mget_image_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [parent_label(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files]\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Filter out classes with only one member\u001b[39;00m\n",
      "File \u001b[1;32me:\\Users\\Dalton\\anaconda3\\envs\\plant_inspector\\lib\\site-packages\\fastai\\data\\transforms.py:61\u001b[0m, in \u001b[0;36mget_image_files\u001b[1;34m(path, recurse, folders)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_image_files\u001b[39m(path, recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, folders\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet image files in `path` recursively, only in `folders`, if specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_extensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecurse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecurse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolders\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Users\\Dalton\\anaconda3\\envs\\plant_inspector\\lib\\site-packages\\fastai\\data\\transforms.py:32\u001b[0m, in \u001b[0;36mget_files\u001b[1;34m(path, extensions, recurse, folders, followlinks)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_files\u001b[39m(path, extensions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, folders\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, followlinks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet all the files in `path` with optional `extensions`, optionally with `recurse`, only in `folders`, if specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 32\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     folders\u001b[38;5;241m=\u001b[39mL(folders)\n\u001b[0;32m     34\u001b[0m     extensions \u001b[38;5;241m=\u001b[39m setify(extensions)\n",
      "File \u001b[1;32me:\\Users\\Dalton\\anaconda3\\envs\\plant_inspector\\lib\\pathlib.py:960\u001b[0m, in \u001b[0;36mPath.__new__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Path:\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m WindowsPath \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m PosixPath\n\u001b[1;32m--> 960\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_parts\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flavour\u001b[38;5;241m.\u001b[39mis_supported:\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot instantiate \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m on your system\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    963\u001b[0m                               \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,))\n",
      "File \u001b[1;32me:\\Users\\Dalton\\anaconda3\\envs\\plant_inspector\\lib\\pathlib.py:594\u001b[0m, in \u001b[0;36mPurePath._from_parts\u001b[1;34m(cls, args)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_parts\u001b[39m(\u001b[38;5;28mcls\u001b[39m, args):\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;66;03m# We need to call _parse_args on the instance, so as to get the\u001b[39;00m\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;66;03m# right flavour.\u001b[39;00m\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m--> 594\u001b[0m     drv, root, parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drv \u001b[38;5;241m=\u001b[39m drv\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root \u001b[38;5;241m=\u001b[39m root\n",
      "File \u001b[1;32me:\\Users\\Dalton\\anaconda3\\envs\\plant_inspector\\lib\\pathlib.py:578\u001b[0m, in \u001b[0;36mPurePath._parse_args\u001b[1;34m(cls, args)\u001b[0m\n\u001b[0;32m    576\u001b[0m     parts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39m_parts\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 578\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001b[39;00m\n\u001b[0;32m    581\u001b[0m         parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(a))\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not float"
     ]
    }
   ],
   "source": [
    "\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=dls.c)\n",
    "learn = Learner(dls, model, metrics=accuracy)\n",
    "learn.fine_tune(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_model_to_new_dls(learn, dls):\n",
    "    # Update the learner's dataloaders\n",
    "    learn.dls = dls\n",
    "    # Get the number of classes in the new dataset\n",
    "    num_classes_new = dls.c\n",
    "    # Replace the final layer of the model to match the new number of classes\n",
    "    # Assuming the final layer is named 'classifier' which is common in timm models\n",
    "    # Note: The naming might vary, so ensure to adjust according to your model's architecture\n",
    "    learn.model.classifier = nn.Linear(learn.model.classifier.in_features, num_classes_new)\n",
    "    # Now you can evaluate the model on the new dataset\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2 = adapt_model_to_new_dls(learn, dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.fine_tune(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteratively_train_on_dataset_fractions(train_pcts = [0.1, 0.25, 0.5, 0.65], replicates=1, dataset_path):\n",
    "    results_table = pd.DataFrame(columns=['train_pct', 'acc'])\n",
    "    for train_pct in train_pcts:\n",
    "        print(f'Creating DL: {train_pct}')\n",
    "        dls = create_dls(train_pct, dataset_path)\n",
    "        for replicate in range(replicates): # repeat training and average results for increased accuracy \n",
    "            print(f'{train_pct} replicate {replicate}')\n",
    "            # fine tune model\n",
    "            model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=dls.c)\n",
    "            learn = Learner(dls, model, metrics=accuracy)\n",
    "            learn.fine_tune(epochs=15)\n",
    "            val_acc = learn.recorder.values[-1][2]\n",
    "            row = pd.DataFrame({'train_pct': train_pct, 'acc': val_acc}, index=[0])\n",
    "            results_table = pd.concat([results_table, row])\n",
    "    mean_table = get_mean_table(results_table)\n",
    "    return mean_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pcts = [0.1, 0.25, 0.5, 0.65]\n",
    "replicates = 3\n",
    "results_table = pd.DataFrame(columns=['train_pct', 'acc'])\n",
    "for train_pct in train_pcts:\n",
    "    print(f'Creating DL: {train_pct}')\n",
    "    dls = create_dls(train_pct)\n",
    "    for replicate in range(replicates): # repeat training and average results for increased accuracy \n",
    "        print(f'{train_pct} replicate {replicate}')\n",
    "        # fine tune model\n",
    "        model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=dls.c)\n",
    "        learn = Learner(dls, model, metrics=accuracy)\n",
    "        learn.fine_tune(epochs=15)\n",
    "        val_acc = learn.recorder.values[-1][2]\n",
    "        row = pd.DataFrame({'train_pct': train_pct, 'acc': val_acc}, index=[0])\n",
    "        results_table = pd.concat([results_table, row])\n",
    "\n",
    "mean_table = get_mean_table(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial = dataset_forecast(mean_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_of_data = 0.9\n",
    "predicted_accuracy = polynomial(percentage_of_data)\n",
    "predicted_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pcts = [0.9]\n",
    "replicates = 3\n",
    "results_table = pd.DataFrame(columns=['train_pct', 'acc'])\n",
    "for train_pct in train_pcts:\n",
    "    print(f'Creating DL: {train_pct}')\n",
    "    dls = create_dls(train_pct)\n",
    "    for replicate in range(replicates): # repeat training and average results for increased accuracy \n",
    "        print(f'{train_pct} replicate {replicate}')\n",
    "        # fine tune model\n",
    "        model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=dls.c)\n",
    "        learn = Learner(dls, model, metrics=accuracy)\n",
    "        learn.fine_tune(epochs=15)\n",
    "        val_acc = learn.recorder.values[-1][2]\n",
    "        row = pd.DataFrame({'train_pct': train_pct, 'acc': val_acc}, index=[0])\n",
    "        results_table = pd.concat([results_table, row])\n",
    "\n",
    "mean_table = pd.concat([mean_table, get_mean_table(results_table)])\n",
    "mean_table = mean_table.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot polynomial here\n",
    "polynomial = dataset_forecast(mean_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_of_data = 0.95\n",
    "predicted_accuracy = polynomial(percentage_of_data)\n",
    "predicted_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet-18\n",
    "# epoch\ttrain_loss\tvalid_loss\taccuracy\ttime\n",
    "# 0\t2.329669\t2.175517\t0.398039\t04:44\n",
    "# 1\t2.047739\t1.710715\t0.527451\t04:47\n",
    "# 2\t1.696105\t1.822478\t0.431373\t04:57\n",
    "# 3\t1.373082\t1.125379\t0.621569\t05:14\n",
    "# 4\t1.118939\t1.178962\t0.613725\t05:16\n",
    "# 5\t0.903016\t1.063396\t0.656863\t05:16\n",
    "# 6\t0.726309\t0.970530\t0.662745\t05:16\n",
    "# 7\t0.587566\t0.937186\t0.670588\t05:15\n",
    "# 8\t0.492905\t0.925825\t0.688235\t05:04\n",
    "# 9\t0.435941\t0.922592\t0.692157\t04:56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fine_tuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pcts = [0.1, 0.25, 0.5, 0.65]\n",
    "replicates = 3\n",
    "field_plant_results_table = pd.DataFrame(columns=['train_pct', 'acc'])\n",
    "for train_pct in train_pcts:\n",
    "    print(f'Creating DL: {train_pct}')\n",
    "    dls = create_dls(train_pct, 'plantvillage-dataset/color')\n",
    "    for replicate in range(replicates): # repeat training and average results for increased accuracy \n",
    "        print(f'{train_pct} replicate {replicate}')\n",
    "        # fine tune model\n",
    "        model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=dls.c)\n",
    "        learn = Learner(dls, model, metrics=accuracy)\n",
    "        learn.fine_tune(epochs=15)\n",
    "        val_acc = learn.recorder.values[-1][2]\n",
    "        row = pd.DataFrame({'train_pct': train_pct, 'acc': val_acc}, index=[0])\n",
    "        field_plant_results_table = pd.concat([field_plant_results_table, row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial = dataset_forecast(field_plant_results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pcts = [0.1, 0.25, 0.5, 0.65]\n",
    "replicates = 3\n",
    "field_plant_results_table = pd.DataFrame(columns=['train_pct', 'acc'])\n",
    "for train_pct in train_pcts:\n",
    "    print(f'Creating DL: {train_pct}')\n",
    "    dls = create_dls(train_pct, 'plantvillage-dataset/segmented')\n",
    "    for replicate in range(replicates): # repeat training and average results for increased accuracy \n",
    "        print(f'{train_pct} replicate {replicate}')\n",
    "        # fine tune model\n",
    "        model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=dls.c)\n",
    "        learn = Learner(dls, model, metrics=accuracy)\n",
    "        learn.fine_tune(epochs=15)\n",
    "        val_acc = learn.recorder.values[-1][2]\n",
    "        row = pd.DataFrame({'train_pct': train_pct, 'acc': val_acc}, index=[0])\n",
    "        field_plant_results_table = pd.concat([field_plant_results_table, row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = create_dls(0.8, 'plantvillage-dataset/segmented')\n",
    "# for replicate in range(replicates): # repeat training and average results for increased accuracy \n",
    "# print(f'{train_pct} replicate {replicate}')\n",
    "# # fine tune model\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=dls.c)\n",
    "learn = Learner(dls, model, metrics=accuracy)\n",
    "learn.fine_tune(epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = create_dls(0.8, 'plantvillage-dataset/color')\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=dls.c)\n",
    "learn = Learner(dls, model, metrics=accuracy)\n",
    "learn.fine_tune(epochs=1)\n",
    "learn.recorder.plot_loss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new dataset\n",
    "dls = create_dls_stratified(0.5, 'FieldPlant-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2 = adapt_model_to_new_dls(learn, dls)    \n",
    "learn2.validate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plant_inspector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
